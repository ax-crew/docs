---
title: Streaming Responses
description: Learn how to use streaming responses with AxCrew agents
---

## Understanding Streaming Responses

AxCrew supports streaming responses from agents, allowing you to receive and process agent outputs in real-time. This is particularly useful for:

- Long-running tasks where you want to show progress
- Interactive applications that need to display responses as they're generated
- Improving perceived responsiveness of your application
- Providing immediate feedback to users

## Basic Streaming Usage

To use streaming responses, you pass an `onStream` callback in the options object when calling an agent's `forward` method:

```typescript
import { AxCrew } from '@amitdeshmukh/ax-crew';

// Create and initialize crew
const crew = new AxCrew('./agentConfig.json');
await crew.addAgentsToCrew(['Planner']);

const planner = crew.agents.get('Planner');

// Stream responses using the forward method
await planner.forward(
  { task: "Create a detailed plan for a website" },
  {
    onStream: (chunk) => {
      // Process each chunk of the response as it arrives
      console.log('Received chunk:', chunk);
      
      // Or directly update UI elements in real-time
      document.getElementById('response').innerText += chunk;
    }
  }
);
```

The `onStream` callback receives text chunks as they're generated by the AI provider, allowing you to process them as soon as they arrive.

## Streaming with Sub-agents

You can also use streaming when one agent calls another agent:

```typescript
// Manager agent using Planner agent with streaming
await manager.forward(
  { task: "Solve this complex problem step by step" },
  {
    onStream: (chunk) => {
      // Display the response in real-time
      process.stdout.write(chunk);
    }
  }
);
```

## Advanced Streaming Usage

Here's a more advanced example showing how to handle streaming in a web application:

```typescript
import { AxCrew, AxCrewFunctions } from '@amitdeshmukh/ax-crew';

// Initialize crew
const crew = new AxCrew('./agentConfig.json', AxCrewFunctions);
await crew.addAgentsToCrew(['ContentWriter']);

const writer = crew.agents.get('ContentWriter');

// Reference to UI element where the response will be displayed
const responseElement = document.getElementById('response');
const loadingElement = document.getElementById('loading-indicator');

// Show loading indicator
loadingElement.style.display = 'block';

// Stream responses to UI with typing effect
let fullResponse = '';
let typingTimer;

try {
  await writer.forward(
    { 
      topic: "Artificial Intelligence", 
      length: "500 words",
      style: "informative" 
    },
    {
      onStream: (chunk) => {
        fullResponse += chunk;
        
        // Clear any pending typing timers
        clearTimeout(typingTimer);
        
        // Create typing effect with a small delay
        typingTimer = setTimeout(() => {
          responseElement.innerText = fullResponse;
          
          // Auto-scroll to bottom to show latest content
          responseElement.scrollTop = responseElement.scrollHeight;
        }, 50);
      }
    }
  );
  
  // Hide loading indicator when complete
  loadingElement.style.display = 'none';
} catch (error) {
  console.error('Error receiving stream:', error);
  responseElement.innerHTML += `<p class="error">Error: ${error.message}</p>`;
  loadingElement.style.display = 'none';
}
```

## Using Streaming with Different AI Providers

Streaming behavior may vary slightly between different AI providers:

### OpenAI

OpenAI sends small chunks of text as they're generated:

```typescript
await openaiAgent.forward(
  { prompt: "Write a short story" },
  {
    onStream: (chunk) => {
      // OpenAI typically sends very small chunks (often single tokens)
      process.stdout.write(chunk);
    }
  }
);
```

### Anthropic Claude

Anthropic Claude typically sends larger chunks of text:

```typescript
await claudeAgent.forward(
  { prompt: "Explain quantum computing" },
  {
    onStream: (chunk) => {
      // Claude may send larger text chunks
      process.stdout.write(chunk);
    }
  }
);
```

### Google Gemini

Google Gemini provides a stream of text chunks:

```typescript
await geminiAgent.forward(
  { prompt: "List 10 facts about space" },
  {
    onStream: (chunk) => {
      process.stdout.write(chunk);
    }
  }
);
```

## Best Practices for Streaming

1. **Handle Errors**: Always wrap streaming code in try/catch blocks to handle potential network or API errors
2. **Buffer Control**: Consider buffering small chunks for smoother UI updates
3. **State Management**: Update your application state as chunks arrive for reactive UIs
4. **Rate Limiting**: Be mindful of how quickly you update the UI to avoid performance issues
5. **Parsing Considerations**: Remember that chunks might split in the middle of words, sentences, or even UTF-8 characters
6. **Complete Responses**: Store the complete response for post-processing once streaming is finished

## Streaming with Cost Tracking

Even when using streaming, AxCrew still tracks usage costs correctly:

```typescript
import { AxCrew } from '@amitdeshmukh/ax-crew';

const crew = new AxCrew('./agentConfig.json');
await crew.addAgentsToCrew(['ContentWriter']);

const writer = crew.agents.get('ContentWriter');

// Use streaming
await writer.forward(
  { topic: "Machine Learning" },
  {
    onStream: (chunk) => {
      process.stdout.write(chunk);
    }
  }
);

// Get cost info after streaming completes
const cost = writer.getLastUsageCost();
console.log('Usage cost:', cost);
```

The cost tracking includes:
- Total tokens used
- Prompt and completion token counts
- Cost breakdown by token type
- Accurate pricing based on the provider and model used

## Limitations

While streaming provides many benefits, it's important to be aware of some limitations:

1. **Function Calls**: When an agent uses functions (tools), some providers may temporarily pause the stream while the function is executed
2. **Formatting**: Markdown, code formatting, and other styled content may appear in pieces before the complete format is visible
3. **Provider Support**: Not all AI providers support streaming equally well
4. **Network Reliability**: Streaming is more susceptible to network hiccups than single requests

## Example: Collaborative Document Creation

Here's a complete example showing how to use streaming to create a collaborative document:

```typescript
import { AxCrew, AxCrewFunctions } from '@amitdeshmukh/ax-crew';

// Initialize crew with multiple agents
const crew = new AxCrew('./agentConfig.json', AxCrewFunctions);
await crew.addAgentsToCrew(['Outliner', 'ContentWriter', 'Editor']);

// Get agent instances
const outliner = crew.agents.get('Outliner');
const writer = crew.agents.get('ContentWriter');
const editor = crew.agents.get('Editor');

// User request
const topic = "The Future of Renewable Energy";

console.log(`Creating document on: ${topic}\n`);

// Step 1: Create outline with streaming
console.log("Generating outline...");
let outline = '';
await outliner.forward(
  { topic },
  {
    onStream: (chunk) => {
      outline += chunk;
      process.stdout.write(chunk);
    }
  }
);

// Store outline in state
crew.state.set('document.outline', outline);
console.log("\n\nOutline complete!\n");

// Step 2: Generate content for each section with streaming
console.log("Writing content based on outline...");
let content = '';
await writer.forward(
  { 
    topic,
    outline: crew.state.get('document.outline')
  },
  {
    onStream: (chunk) => {
      content += chunk;
      process.stdout.write(chunk);
    }
  }
);

// Store content in state
crew.state.set('document.content', content);
console.log("\n\nContent complete!\n");

// Step 3: Edit and improve the document with streaming
console.log("Editing document...");
let finalDocument = '';
await editor.forward(
  {
    content: crew.state.get('document.content'),
    instructions: "Improve clarity, fix grammar, and ensure professional tone."
  },
  {
    onStream: (chunk) => {
      finalDocument += chunk;
      process.stdout.write(chunk);
    }
  }
);

// Store final document in state
crew.state.set('document.final', finalDocument);
console.log("\n\nEditing complete!\n");

// Calculate total tokens and cost
const totalCosts = crew.getAggregatedCosts();
console.log("\nDocument creation complete!");
console.log(`Total tokens used: ${totalCosts.aggregatedMetrics.totalTokens}`);
console.log(`Total cost: $${totalCosts.totalCost}`);
``` 